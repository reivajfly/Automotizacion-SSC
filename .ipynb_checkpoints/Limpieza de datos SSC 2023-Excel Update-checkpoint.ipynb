{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACTUALIZACIÓN SERVICIO SOCIAL COMUNITARIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import date\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuarios que han ingresado al curso: (2950, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>username</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>email</th>\n",
       "      <th>city</th>\n",
       "      <th>description</th>\n",
       "      <th>lst_access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>user</td>\n",
       "      <td>Santander</td>\n",
       "      <td>Skills</td>\n",
       "      <td>sistemas@fese.org.mx</td>\n",
       "      <td>CIUDAD DE México</td>\n",
       "      <td></td>\n",
       "      <td>2023-10-05 19:20:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137248</td>\n",
       "      <td>co488798@uaeh.edu.mx</td>\n",
       "      <td>MARÍA JOSÉ</td>\n",
       "      <td>CORTES FLORES</td>\n",
       "      <td>co488798@uaeh.edu.mx</td>\n",
       "      <td>Hidalgo</td>\n",
       "      <td>MX - UAEH - Universidad Autónoma del Estado de...</td>\n",
       "      <td>2023-02-10 22:55:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137241</td>\n",
       "      <td>prodriguezmendiola@gmail.com</td>\n",
       "      <td>Pablo</td>\n",
       "      <td>Rodríguez Mendiola</td>\n",
       "      <td>prodriguezmendiola@gmail.com</td>\n",
       "      <td>Veracruz</td>\n",
       "      <td>MX - UPAV - Universidad Popular Autónoma de Ve...</td>\n",
       "      <td>2023-02-14 06:08:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137272</td>\n",
       "      <td>tonyrito.lol@gmail.com</td>\n",
       "      <td>Antonio</td>\n",
       "      <td>De Santiago</td>\n",
       "      <td>tonyrito.lol@gmail.com</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>MX - UACJ - Universidad Autónoma de Ciudad Juárez</td>\n",
       "      <td>2023-02-11 03:24:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137238</td>\n",
       "      <td>vianeyblas33@gmail.com</td>\n",
       "      <td>Daniela Vianey</td>\n",
       "      <td>Blas Juárez</td>\n",
       "      <td>vianeyblas33@gmail.com</td>\n",
       "      <td>Oaxaca</td>\n",
       "      <td>MX - Universidad La Salle Oaxaca</td>\n",
       "      <td>2023-02-17 16:48:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId                      username       firstname            lastname  \\\n",
       "0       2                          user       Santander              Skills   \n",
       "1  137248          co488798@uaeh.edu.mx      MARÍA JOSÉ       CORTES FLORES   \n",
       "2  137241  prodriguezmendiola@gmail.com           Pablo  Rodríguez Mendiola   \n",
       "3  137272        tonyrito.lol@gmail.com         Antonio         De Santiago   \n",
       "4  137238        vianeyblas33@gmail.com  Daniela Vianey         Blas Juárez   \n",
       "\n",
       "                          email              city  \\\n",
       "0          sistemas@fese.org.mx  CIUDAD DE México   \n",
       "1          co488798@uaeh.edu.mx           Hidalgo   \n",
       "2  prodriguezmendiola@gmail.com          Veracruz   \n",
       "3        tonyrito.lol@gmail.com         Chihuahua   \n",
       "4        vianeyblas33@gmail.com            Oaxaca   \n",
       "\n",
       "                                         description          lst_access  \n",
       "0                                                    2023-10-05 19:20:58  \n",
       "1  MX - UAEH - Universidad Autónoma del Estado de... 2023-02-10 22:55:09  \n",
       "2  MX - UPAV - Universidad Popular Autónoma de Ve... 2023-02-14 06:08:17  \n",
       "3  MX - UACJ - Universidad Autónoma de Ciudad Juárez 2023-02-11 03:24:49  \n",
       "4                   MX - Universidad La Salle Oaxaca 2023-02-17 16:48:25  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    # Establecer la conexión con la base de datos\n",
    "    cnx = mysql.connector.connect(user='fese', password='F3$e.20-21',\n",
    "                                  host='santandermoodle2022.cvxcmwgafwb2.us-east-2.rds.amazonaws.com',\n",
    "                                  database='bitnami_moodle')\n",
    "    cursor = cnx.cursor()\n",
    "    \n",
    "    # Definir la consulta SQL\n",
    "    query = \"SELECT mdl_user.id, username, firstname, lastname, email, city, description, \\\n",
    "            from_unixtime(timeaccess) as acceso FROM bitnami_moodle.mdl_user_lastaccess \\\n",
    "            left join mdl_user ON(mdl_user_lastaccess.userid=mdl_user.id) \\\n",
    "            where courseid=122;\"\n",
    "    \n",
    "    # Ejecutar la consulta\n",
    "    cursor.execute(query)\n",
    "    \n",
    "    # Convertir los resultados en un DataFrame de pandas\n",
    "    result_ingresos = pd.DataFrame(cursor.fetchall())\n",
    "    result_ingresos.columns = ['userId','username','firstname','lastname','email','city','description','lst_access']\n",
    "    \n",
    "    # Imprimir el número de usuarios que han ingresado al curso\n",
    "    print(\"Usuarios que han ingresado al curso: {}\".format(result_ingresos.shape))\n",
    "    \n",
    "    \n",
    "    \n",
    "except mysql.connector.Error as err:\n",
    "    # Manejo de errores de la conexión a la base de datos\n",
    "    if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "        print(\"Algo está mal con tu nombre de usuario o contraseña\")\n",
    "    elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "        print(\"La base de datos no existe\")\n",
    "    else:\n",
    "        print(err)\n",
    "finally:\n",
    "    # Cerrar el cursor y la conexión a la base de datos\n",
    "    if 'cursor' in locals() and cursor:\n",
    "        cursor.close()\n",
    "    if 'cnx' in locals() and cnx:\n",
    "        cnx.close()\n",
    "        \n",
    "# Imprimir las primeras filas del DataFrame\n",
    "result_ingresos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'consolidado.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3148\\2171538446.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Leer el archivo consolidado desde un archivo CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mconsolidado\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"consolidado.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Leer el archivo de actualización desde un archivo Excel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\grom_\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\grom_\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\grom_\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\grom_\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\grom_\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\grom_\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'consolidado.csv'"
     ]
    }
   ],
   "source": [
    "# Lectura de archivos fuente\n",
    "file_update = \"update_211123.xlsx\"  # Nombre del archivo de actualización\n",
    "\n",
    "# Leer el archivo consolidado desde un archivo CSV\n",
    "consolidado = pd.read_csv(\"consolidado.csv\")\n",
    "\n",
    "# Leer el archivo de actualización desde un archivo Excel\n",
    "# Asegúrate de que el archivo y la pestaña 'data' existen en la ruta especificada\n",
    "# El parámetro header=0 indica que la primera fila (fila 0 en la indexación basada en cero) se debe usar como nombre de las columnas\n",
    "update_file = pd.read_excel(f'actualizaciones/{file_update}', sheet_name='data', header=0)\n",
    "\n",
    "# Eliminar los espacios sobrantes al principio y al final en todas las columnas\n",
    "update_file = update_file.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Directorio de salida\n",
    "path_gen = \"output/\"  # Ruta del directorio de salida\n",
    "\n",
    "# Obtener la fecha de hoy en formato de cadena\n",
    "date_today = str(date.today())\n",
    "\n",
    "# Preparar los nombres de los archivos de salida\n",
    "# Estos archivos se guardarán en la carpeta 'output' con la fecha de hoy en sus nombres\n",
    "file_output_csv = f'{path_gen}mailchimpTest-{date_today}.csv'  # Archivo de salida para Mailchimp\n",
    "file_upload_users_csv = f'{path_gen}altasTest-{date_today}.csv'  # Archivo de salida para las altas de usuarios\n",
    "# Imprimir el número de estudiantes en el archivo consolidado\n",
    "# La función shape[0] devuelve el número de filas en el DataFrame, que corresponde al número de estudiantes\n",
    "print(f\"Estudiantes en consolidado: {consolidado.shape[0]}\")\n",
    "\n",
    "# Imprimir el número de estudiantes en el archivo de actualización\n",
    "print(f\"Estudiantes en actualización: {update_file.shape[0]}\")\n",
    "\n",
    "# Identificar los nuevos registros en el archivo de actualización\n",
    "# Esto se hace buscando los emails en el archivo de actualización que no están en el archivo consolidado\n",
    "nuevos_registros = update_file[~update_file[\"email\"].isin(consolidado[\"username\"])]\n",
    "\n",
    "# Imprimir el número de nuevos estudiantes por agregar\n",
    "print(f\"Nuevos estudiantes por agregar: {nuevos_registros.shape[0]}\")\n",
    "# Imprimir los nombres de las columnas en el DataFrame de actualización\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nuevos_registros' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1784\\2729243996.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Seleccionamos las columnas necesarias de los nuevos registros\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m df_columnas = nuevos_registros[[\"Terms Apply Request Date\", \"email\",\"name\", \"lastName\", \"email\",\\\n\u001b[0m\u001b[0;32m      3\u001b[0m                                 \u001b[1;34m\"university\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"phone\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"otherUniversity\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Selecciona tu entidad federativa\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                \u001b[1;34m\"Número de matricula\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"sex\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Nombre completo de tu carrera\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                 \u001b[1;34m\"Periodo que cursa actualmente Semestre/Cuatrimestre/Trimestre \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nuevos_registros' is not defined"
     ]
    }
   ],
   "source": [
    "# Seleccionamos las columnas necesarias de los nuevos registros\n",
    "df_columnas = nuevos_registros[[\"Terms Apply Request Date\", \"email\",\"name\", \"lastName\", \"email\",\\\n",
    "                                \"university\",\"phone\", \"otherUniversity\", \"Selecciona tu entidad federativa\",\\\n",
    "                               \"Número de matricula\",\"sex\",\"Nombre completo de tu carrera\",\\\n",
    "                                \"Periodo que cursa actualmente Semestre/Cuatrimestre/Trimestre \",\\\n",
    "                                \"Selecciona tu perfil\",\"¿Cómo te enteraste de esta convocatoria?\",\"dniPassport\",\\\n",
    "                               \"Selecciona el área a la que se vinculan tus estudios actuales o más recientes\"]]\n",
    "\n",
    "# Renombramos las columnas para que coincidan con el formato de Moodle\n",
    "df_columnas.columns = [\"Date\", \"username\",\"name\",\"lastName\",\"email\",\"university\",\"phone\",\"otherUniversity\",\"Entidad\",\\\n",
    "                      \"matricula\",\"sexo\",\"carrera\",\"periodo\",\"perfil\",\"medio\",\"dni\",\"area_conocimiento\"]\n",
    "\n",
    "# Insertamos nuevas columnas con datos predefinidos\n",
    "df_columnas.insert(2, \"password\", \"SsC$2023\", allow_duplicates=False)  # Contraseña predefinida\n",
    "df_columnas.insert(6, \"course1\", \"SSC2023\", allow_duplicates=False)  # Curso predefinido\n",
    "df_columnas.insert(11, \"open_mail\", \"No\", allow_duplicates=False)  # Configuración de correo electrónico predefinida\n",
    "\n",
    "# Imprimimos el número de filas en el DataFrame de salida, que corresponde al número de estudiantes\n",
    "print(f\"Archivo de salida: {df_columnas.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_columnas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1784\\1634586778.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Si la columna 'university' está vacía, asignamos el valor de 'otherUniversity' a la columna 'university'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#df_columnas['university'] = df_columnas.apply(lambda row: row['otherUniversity'] if pd.isna(row['university']) else row['university'], axis=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdf_columnas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_columnas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'university'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'university'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_columnas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_columnas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'university'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'otherUniversity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m# Eliminamos la columna 'otherUniversity' ya que no es necesaria\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mdel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_columnas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'otherUniversity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_columnas' is not defined"
     ]
    }
   ],
   "source": [
    "# Creamos un diccionario vacío para almacenar las universidades\n",
    "universidad = {}\n",
    "\n",
    "# Recorremos el DataFrame fila por fila\n",
    "#for i in range(len(df_columnas)):\n",
    "    # Si la columna 'university' está vacía\n",
    "#    if pd.isna(df_columnas.iloc[i]['university']):\n",
    "#        # Asignamos el valor de 'otherUniversity' a la columna 'university'\n",
    "#        df_columnas.at[df_columnas.index[i],'university'] = df_columnas.iloc[i]['otherUniversity']\n",
    "# Si la columna 'university' está vacía, asignamos el valor de 'otherUniversity' a la columna 'university'\n",
    "#df_columnas['university'] = df_columnas.apply(lambda row: row['otherUniversity'] if pd.isna(row['university']) else row['university'], axis=1)\n",
    "df_columnas.loc[pd.isna(df_columnas['university']), 'university'] = df_columnas.loc[pd.isna(df_columnas['university']), 'otherUniversity']# Eliminamos la columna 'otherUniversity' ya que no es necesaria\n",
    "del(df_columnas['otherUniversity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'consolidado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1784\\2346968696.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Crear un DataFrame con los usuarios de Mailchimp que han ingresado\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_usuarios_mailchimp_ingreso\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconsolidado\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconsolidado\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'email'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_ingresos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'email'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Crear un DataFrame con los usuarios de Mailchimp que no han ingresado\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_usuarios_mailchimp_sin_ingreso\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconsolidado\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mconsolidado\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'email'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_ingresos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'email'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'consolidado' is not defined"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame con los usuarios de Mailchimp que han ingresado\n",
    "df_usuarios_mailchimp_ingreso = consolidado[consolidado['email'].isin(result_ingresos['email'])].copy()\n",
    "\n",
    "# Crear un DataFrame con los usuarios de Mailchimp que no han ingresado\n",
    "df_usuarios_mailchimp_sin_ingreso = consolidado[~consolidado['email'].isin(result_ingresos['email'])].copy()\n",
    "\n",
    "# Crear un DataFrame con los usuarios que han ingresado al sistema\n",
    "df_usuarios_ingreso_sistema = result_ingresos.copy()\n",
    "\n",
    "# Guardar el DataFrame de usuarios que han ingresado al sistema en un archivo CSV\n",
    "df_usuarios_ingreso_sistema.to_csv(\"ingreso.csv\", index = False)\n",
    "\n",
    "# Imprimir el número de filas (usuarios) en cada DataFrame\n",
    "print(f\"consolidado: {consolidado.shape[0]}\")\n",
    "print(f\"df_usuarios_mailchimp_ingreso: {df_usuarios_mailchimp_ingreso.shape[0]}\")\n",
    "print(f\"df_usuarios_mailchimp_sin_ingreso: {df_usuarios_mailchimp_sin_ingreso.shape[0]}\")\n",
    "print(f\"df_usuarios_ingreso_sistema: {df_usuarios_ingreso_sistema.shape[0]}\")\n",
    "\n",
    "# Añadir una nueva columna 'open_mail' al DataFrame de usuarios de Mailchimp que han ingresado, con todos los valores establecidos en \"Sí\"\n",
    "df_usuarios_mailchimp_ingreso.loc[:, 'open_mail'] = \"Sí\"\n",
    "\n",
    "# Concatenar los DataFrames 'consolidado' y 'df_columnas', eliminar los duplicados basándose en la columna 'email' y reiniciar el índice\n",
    "final_dataframe = pd.concat([consolidado, df_columnas]).drop_duplicates(subset='email', keep='last').reset_index(drop=True)\n",
    "\n",
    "# Concatenar los DataFrames 'df_columnas', 'df_usuarios_mailchimp_sin_ingreso' y 'df_usuarios_mailchimp_ingreso', eliminar los duplicados basándose en la columna 'email' y reiniciar el índice\n",
    "df_mailchimp = pd.concat([df_columnas, df_usuarios_mailchimp_sin_ingreso, df_usuarios_mailchimp_ingreso]).drop_duplicates(subset='email', keep='last').reset_index(drop=True)\n",
    "\n",
    "# Imprimir el número de filas y columnas en cada DataFrame\n",
    "print(f\"Shape of final_dataframe: {final_dataframe.shape}\")\n",
    "print(f\"Shape of df_mailchimp: {df_mailchimp.shape}\")\n",
    "\n",
    "# Eliminar columnas innecesarias\n",
    "df_mailchimp.drop(['Date', 'sexo', 'carrera', 'periodo', 'perfil', 'medio', 'dni', 'matricula', 'area_conocimiento'], axis=1, inplace=True)\n",
    "\n",
    "# Renombrar columnas\n",
    "df_mailchimp.columns = [\"email\",\"password\",\"firstname\",\"lastName\",\"usuario\",\"curso\",\"IES\",\"phone\",\"Entidad\",\"Correoabierto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1784\\632576102.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Generación del archivo consolidado\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfinal_dataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'consolidado.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Generación del archivo Mailchimp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_mailchimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_output_csv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "# Generación del archivo consolidado\n",
    "final_dataframe.to_csv('consolidado.csv', index=False)\n",
    "\n",
    "# Generación del archivo Mailchimp\n",
    "df_mailchimp.to_csv(file_output_csv, index=False)\n",
    "print(\"Archivo Mailchimp generado\", file_output_csv)\n",
    "\n",
    "# Crear una copia del DataFrame 'df_columnas'\n",
    "df_columnas_copy = df_columnas.copy()\n",
    "\n",
    "# Borrado de columnas\n",
    "df_columnas_copy.drop(['Date', 'open_mail'], axis=1, inplace=True)\n",
    "\n",
    "# Renombrar columnas\n",
    "df_columnas_copy.columns = ['username', 'password', 'firstname', 'lastName', 'email', 'course1',\\\n",
    "                       'description','phone1','city','skype','yahoo','address','icq','msn',\\\n",
    "                       'url','idnumber','department']\n",
    "\n",
    "# Escritura_archivo_salida\n",
    "df_columnas_copy.to_csv(file_upload_users_csv, index=False)\n",
    "print(\"Archivo Update  generado\", file_output_csv)\n",
    "\n",
    "# Imprimir la forma del DataFrame\n",
    "print(df_columnas_copy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
